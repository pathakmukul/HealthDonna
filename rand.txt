import streamlit as st
from dotenv import load_dotenv
import os
import openai
import re
from pathlib import Path
from sys_prompt import system_prompt4
from LLMCall import GroqCalls
from groq import Groq
from rag_tool import rag_tool, process_documents
from langchain.schema import Document
import uuid
import pickle
import pandas as pd
import io

# Load environment variables and initialize OpenAI client
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

class Agent:
    def __init__(self, client: openai, system: str = ""):
        self.client = client
        self.system = system
        self.messages: list = []
        if self.system:
            self.messages.append({"role": "system", "content": system})

    def __call__(self, message=""):
        if message:
            self.messages.append({"role": "user", "content": message})
        result = self.execute()
        self.messages.append({"role": "assistant", "content": result})
        return result

    def execute(self):
        completion = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=self.messages,
            temperature=0
        )
        return completion.choices[0].message.content.strip()

# Initialize StreamBuilder with the OpenAI client and the imported system prompt
# st.sidebar.title('Navigation')
# st.sidebar.button('Navigator',)
StreamBuilder = Agent(client=openai, system=system_prompt4)
if 'pages' not in st.session_state:
    st.session_state['pages'] = {}

def essay_writer(topic: str):
    essay = GroqCalls(topic)
    return {'action': 'text', 'content': essay}

def streamlit_coder(description: str):
    code_prompt = f"""
    Write Streamlit code for: {description}
    
    Make sure to include the following at the top of the file:
    from LLMCall import GroqCalls
    
    When using LLM calls, use the GroqCalls function like this:

    response = GroqCalls(prompt)
    Also concatenate the prompt for the tool in prompt variable to customise responses eg:
    prompt = Write summary for user input (and pass prompt or rest of content on which operation is to be performed) "
            response = GroqCalls(prompt)

    Ensure the code is complete and executable.
    """
    code = GroqCalls(code_prompt)
    return {'action': 'code', 'content': code}

def sanitize_code(code: str) -> str:
    lines = code.split('\n')
    sanitized_lines = [line for line in lines if line.strip() not in ['```python', '```']]
    return '\n'.join(sanitized_lines)

def final_reviewer(code: str):
    review_prompt = f"""
    You are a production streamlit app developer. You have been given a streamlit python code which contains
    all the necessary imports and functions. Although its not clean and few features maybe here and there.
    With what has been given to you clean the code reorder it and make it efficient. DONT ADD ANY new element to the code.
    1. Ensure the following imports are at the top of the file:
       from LLMCall import GroqCalls
    2. Make sure all LLM calls use the GroqCalls function correctly:
       response = GroqCalls(prompt)
    3. Ensure proper indentation and correct function structure.
    4. Use correct Streamlit functions and syntax.
    5. Make sure the code is clean, efficient, and executable.
    6. Do not include any explanations or comments in your output.

    Here's the code to review and rewrite:

    {code}

    Please provide only the corrected, executable Streamlit code without any additional text or explanations.
    """
    corrected_code = GroqCalls(review_prompt)
    sanitized_code = sanitize_code(corrected_code)
    return {'action': 'code', 'content': sanitized_code}

def llm_call(prompt: str):
    response = GroqCalls(prompt)
    return {'action': 'llm_response', 'content': response}

def create_rag_page(vectorstore_id, page_name):
    rag_page_content = f"""
import streamlit as st
from rag_tool import load_vectorstore, rag_tool
from pathlib import Path

st.title('RAG Chatbot for {page_name}')

# Load the vectorstore
@st.cache_resource(show_spinner=False)
def get_vectorstore():
    vectorstore_path = Path("vectorstores") / "{vectorstore_id}"
    return load_vectorstore(str(vectorstore_path))

vectorstore = get_vectorstore()

# Initialize chat history for this specific page
chat_history_key = f"chat_history_{vectorstore_id}"
if chat_history_key not in st.session_state:
    st.session_state[chat_history_key] = []

# Display chat history
for message in st.session_state[chat_history_key]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Chat input
if prompt := st.chat_input("Ask a question about the document"):
    # Display user message in chat message container
    with st.chat_message("user"):
        st.markdown(prompt)
    # Add user message to chat history
    st.session_state[chat_history_key].append({{"role": "user", "content": prompt}})

    # Display assistant response in chat message container
    with st.chat_message("assistant"):
        with st.status('Thinking...'):
            response = rag_tool(prompt, vectorstore=vectorstore)
        st.markdown(response)
    # Add assistant response to chat history
    st.session_state[chat_history_key].append({{"role": "assistant", "content": response}})

# Clear chat history button
if st.button("Clear Chat History", key=f"clear_{vectorstore_id}"):
    st.session_state[chat_history_key] = []
    st.experimental_rerun()
    """
    return {'action': 'code', 'content': rag_page_content}

def manage_pages(query: str, uploaded_file):
    actions = {
        "essay_writer": essay_writer,
        "streamlit_coder": streamlit_coder,
        "llm_call": llm_call,
    }
    
    if "build rag" in query.lower():
        if uploaded_file is not None:
            file_content = process_uploaded_file(uploaded_file)
            return [create_rag_page(file_content, uploaded_file.name)]
        else:
            return [{'action': 'text', 'content': "Please upload a document to build a RAG page."}]
    
    next_prompt = query
    page_elements = []
    i = 0
    max_iterations = 10

    while i < max_iterations:
        i += 1
        result = StreamBuilder(next_prompt)
        print(f"Agent response: {result}")  # Print to terminal
        st.write(result)  # Print to Streamlit app
        page_elements.append({'action': 'agent_response', 'content': result})

        if ("PAUSE" in result or "Pause" in result) and ("Action" in result or "action" in result):
            action_search = re.findall(r"(?:Action|action): ([a-z_]+): (.+)", result, re.IGNORECASE)
            if action_search:
                chosen_tool, arg = action_search[0]
                if chosen_tool.lower() in actions:
                    element = actions[chosen_tool.lower()](arg)
                    page_elements.append(element)
                    next_prompt = f"Observation: {chosen_tool} added"
                else:
                    next_prompt = "Observation: Tool not found"
                continue
        if "Answer" in result:
            break

    # Combine all code elements
    combined_code = "\n".join([element['content'] for element in page_elements if element['action'] == 'code'])
    
    # Run final review on the combined code
    reviewed_code = final_reviewer(combined_code)
    
    # Replace all code elements with the reviewed code
    page_elements = [element for element in page_elements if element['action'] != 'code']
    page_elements.append(reviewed_code)

    return page_elements

def load_pages():
    pages_dir = Path("pages")
    if pages_dir.exists():
        for page_file in pages_dir.glob("*.py"):
            page_name = page_file.stem.replace("_", " ").title()
            st.session_state['pages'][page_name] = "loaded"
    print("Loaded pages:", st.session_state['pages'])  # Debug print

def sanitize_function_name(name):
    sanitized = re.sub(r'[^a-zA-Z0-9_]', '_', name)
    if not sanitized[0].isalpha() and sanitized[0] != '_':
        sanitized = '_' + sanitized
    return sanitized

def escape_string(s):
    return s.replace("'", "\\'").replace('"', '\\"')

def save_page(page_name: str, elements: list):
    pages_dir = Path("pages")
    pages_dir.mkdir(exist_ok=True)
    
    page_filename = f"{sanitize_function_name(page_name.lower())}.py"
    page_path = pages_dir / page_filename
    
    with page_path.open("w") as f:
        f.write("import streamlit as st\n")
        f.write("from LLMCall import GroqCalls\n")
        f.write("from rag_tool import rag_tool\n")
        f.write("from langchain.schema import Document\n")
        f.write("import pickle\n")
        f.write("from pathlib import Path\n\n")
        for element in elements:
            if element['action'] == 'text':
                f.write(f"st.markdown('''{escape_string(element['content'])}''')\n\n")
            elif element['action'] == 'code':
                f.write(f"{element['content']}\n\n")
            elif element['action'] == 'llm_response':
                f.write(f"st.text_area('LLM Response', '''{escape_string(element['content'])}''', height=200)\n\n")
    
    # Save vectorstore if it exists
    if len(elements) == 1 and elements[0]['action'] == 'code' and 'vectorstore' in elements[0]:
        vectorstore_path = pages_dir / f"{page_name}_vectorstore.pkl"
        with vectorstore_path.open("wb") as f:
            pickle.dump(elements[0]['vectorstore'], f)
    
    print(f"Page saved to {page_path}")  # Debug print
    return page_path

def process_uploaded_file(uploaded_file):
    if uploaded_file.type == "text/plain":
        return uploaded_file.getvalue().decode("utf-8")
    elif uploaded_file.type == "text/csv":
        df = pd.read_csv(io.StringIO(uploaded_file.getvalue().decode("utf-8")))
        return df.to_string()
    else:
        st.error(f"Unsupported file type: {uploaded_file.type}")
        return None

def create_and_store_vectorstore(file_content, file_name):
    documents = [Document(page_content=file_content, metadata={"source": file_name})]
    
    # Generate a unique ID for this vectorstore
    vectorstore_id = str(uuid.uuid4())
    
    # Create the vectorstore directory
    vectorstore_path = Path("vectorstores") / vectorstore_id
    vectorstore_path.mkdir(parents=True, exist_ok=True)
    
    # Create and persist the vectorstore
    vectorstore = process_documents(documents, persist_directory=str(vectorstore_path))
    
    return vectorstore_id

def home_page():
    st.title('App:red[Smith]')
    st.subheader("Your personal GenAI App Builder!", divider='red')
    st.write("To generate an app, simply describe the app you want to build, and I'll help you create it.")

    page_name = st.text_input("Enter a name for this page:")    
    query = st.text_area("What would you like to add to the page?", "", height=150)
    uploaded_file = st.file_uploader("Choose a file for RAG (optional)", type=["txt", "csv"])
    
    if st.button('Build Page'):
        if page_name:
            if "build rag" in query.lower() and uploaded_file is not None:
                with st.spinner('Processing document... This may take a moment.'):
                    file_content = process_uploaded_file(uploaded_file)
                    if file_content is not None:
                        vectorstore_id = create_and_store_vectorstore(file_content, uploaded_file.name)
                        elements = [create_rag_page(vectorstore_id, uploaded_file.name)]
                    else:
                        st.error("Failed to process the uploaded file.")
                        return
            else:
                elements = manage_pages(query, uploaded_file)
            
            # Display Agent responses and generated content
            for element in elements:
                if element['action'] == 'agent_response':
                    st.subheader("Agent Response:")
                    st.write(element['content'])
                elif element['action'] in ['text', 'llm_response']:
                    st.subheader("Generated Content:")
                    st.write(element['content'])
                elif element['action'] == 'code':
                    st.subheader("Generated Code:")
                    st.code(element['content'], language='python')
            
            page_path = save_page(page_name, elements)
            st.balloons()
            st.toast(f"Page '{page_name}' has been created successfully!")

            st.session_state['pages'][page_name] = "loaded"
            if st.button(f"View '{page_name}' page"):
                st.session_state['current_page'] = page_name

            st.rerun()  # Force a rerun to update the sidebar
        else:
            st.warning("Please enter a name for the page.")

def dynamic_page(page_name):
    if st.session_state['pages'][page_name] == "loaded":
        st.info(f"This is the {page_name} page. Its content is defined in the pages/{sanitize_function_name(page_name.lower())}.py file.")
    else:
        st.error(f"Error: Content for {page_name} not found.")

# Load existing pages when the app starts
load_pages()
home_page()


########################################################################################################################

import streamlit as st
from pathlib import Path
import random
import importlib.util

# List of emojis to use randomly for each page
PAGE_EMOJIS = ["📊", "📈", "🔍", "📝", "🖥️", "📚", "🧠", "🔬", "🎨", "🚀", "💡"]

def load_pages():
    pages = {}
    pages_dir = Path("pages")
    if pages_dir.exists():
        for page_file in pages_dir.glob("*.py"):
            page_name = page_file.stem.replace("_", " ").title()
            pages[page_name] = str(page_file)
    return pages

def create_button_style():
    return """
    <style>
    div.stButton > button:first-child {
        height: 75px;
        width: 100%;
        font-size: 16px;
        font-weight: bold;
    }
    </style>
    """

def load_page_module(page_path):
    spec = importlib.util.spec_from_file_location("page_module", page_path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module

def create_page_button(page_name, page_path, emoji, is_new_app=False):
    st.markdown(create_button_style(), unsafe_allow_html=True)
    button_type = "primary" if is_new_app else "secondary"
    if st.button(f"{emoji} {page_name}", key=f"nav_{page_name}", use_container_width=True, type=button_type):
        st.session_state['current_page'] = page_path
        st.experimental_rerun()

def navigator_page():
    st.title('App:red[Smith] :compass: Navigator')
    st.subheader("Your Personal GenAI App Hub", divider='red')

    pages = load_pages()

    st.subheader("Your Apps")

    # Create buttons for New App and existing pages
    cols = st.columns(3)
    
    # New App button (first in the grid)
    new_app_path = "/Users/mukulpathak/Documents/VSCodeZone/AppSmith/NewApp.py"
    with cols[0]:
        create_page_button("New App", new_app_path, "🔧", is_new_app=True)

    # Create buttons for each existing page
    for i, (page_name, page_path) in enumerate(pages.items(), start=1):
        with cols[i % 3]:
            emoji = random.choice(PAGE_EMOJIS)
            create_page_button(page_name, page_path, emoji)

    if not pages:
        st.info("No apps have been created yet. Use the 'New App' button to create your first app!")

def main():
    if 'current_page' not in st.session_state:
        st.session_state['current_page'] = None

    if st.session_state['current_page'] is None:
        navigator_page()
    else:
        # Load and display the selected page
        page_module = load_page_module(st.session_state['current_page'])
        if hasattr(page_module, 'main'):
            page_module.main()
        else:
            st.error(f"Error: The selected page does not have a 'main' function.")

        if st.button("Back to Navigator"):
            st.session_state['current_page'] = None
            st.experimental_rerun()

if __name__ == "__main__":
    main()


########################################################################################################################

import streamlit as st
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
import os
from dotenv import load_dotenv

def setup_rag():
    load_dotenv()
    openai_api_key = os.getenv("OPENAI_API_KEY")
    llm = ChatOpenAI(temperature=0, max_tokens=1000, model_name="gpt-3.5-turbo", streaming=True)
    return llm

def process_documents(documents, persist_directory):
    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    document_chunks = text_splitter.split_documents(documents)
    embeddings = OpenAIEmbeddings()
    vectorstore = Chroma.from_documents(document_chunks, embeddings, persist_directory=persist_directory)
    vectorstore.persist()
    return vectorstore

def load_vectorstore(persist_directory):
    embeddings = OpenAIEmbeddings()
    return Chroma(persist_directory=persist_directory, embedding_function=embeddings)

def rag_qa(question, vectorstore, chat_history):
    llm = setup_rag()
    qa_chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever())
    response = qa_chain({"question": question, "chat_history": chat_history})
    return response['answer']

def rag_tool(prompt, vectorstore=None):
    if vectorstore is None:
        return "Please provide a processed vectorstore."
    
    if 'rag_chat_history' not in st.session_state:
        st.session_state.rag_chat_history = []
    
    answer = rag_qa(prompt, vectorstore, st.session_state.rag_chat_history)
    st.session_state.rag_chat_history.append((prompt, answer))
    return answer



########################################################################################################################


system_prompt4 = """
You run in a loop of Thought, Action, PAUSE, Observation.
At the end of the loop you output an Answer
Use Thought to describe your thoughts about the question you have been asked.
Use Action to perform one of the actions available to you - then return PAUSE.
Observation will be the result of running those actions.

Your available actions are:

essay_writer:
e.g., essay_writer: The impact of artificial intelligence on modern society
Generates and adds a 500-word essay on the specified topic to the page.

streamlit_coder:
e.g., streamlit_coder: Create a title saying 'Welcome to Our AI App' and add a paragraph introducing the app
Generates Streamlit code for the specified functionality and adds it to the page. This action can be used to create any Streamlit element, including titles, text, headers, buttons, and more complex components.

final_reviewer:
e.g., final_reviewer: [Streamlit code to review]
Reviews the Streamlit code, corrects any issues with indentation, structure, or Streamlit usage, and provides a cleaned-up version of the code. This step is crucial for ensuring the final code is properly formatted and executable.

Code Generation Guidelines:
When generating Streamlit code using the streamlit_coder action, follow these guidelines to ensure a clean and user-friendly experience:
- Focus on creating a clear and intuitive user interface
- for chat use st.chat_input and st.chat_message and things like for message in st.session_state.messages: with st.chat_message(message["role"]): st.write(message["content"])
- Avoid including any backend communication or agent thoughts in the generated code
- Do not use `st.text_area` or similar components to display agent messages or internal communication
- Ensure that the generated code only includes elements that are relevant and meaningful to the end-user
- Use appropriate Streamlit components such as `st.title`, `st.header`, `st.subheader`, `st.write`, and `st.markdown` to structure and present the content
- Provide clear instructions and guidance to the user on how to interact with the app
- Test the generated code to ensure it runs without errors and provides a smooth user experience
- For roles through LLM calls, write detailed prompts. for example: for jira story writer you my use: based on user input create detailed story for jira in details.
Remember, the goal is to create a polished and professional Streamlit app that focuses on the user's needs and hides any internal agent communication.

Example session:

Question: Create a page about AI with a title, an introductory paragraph, a detailed essay, and a button to generate AI facts.
Thought: The user wants a page about AI with several elements. I'll add these elements one by one using the streamlit_coder and essay_writer actions.
Action: streamlit_coder: Create a title saying 'Artificial Intelligence: Shaping Our Future' and add an introductory paragraph about AI's impact on society
PAUSE 

You will be called again with this:

Observation: Code added

Thought: Now I need to add a detailed essay about AI's impact on society.
Action: essay_writer: The impact of artificial intelligence on modern society
PAUSE

You will be called again with this:

Observation: Essay added

Thought: Lastly, I need to add a button to generate AI facts.
Action: streamlit_coder: Create a button that, when clicked, displays a random AI fact using an LLM call
PAUSE

You will be called again with this:

Observation: Code added

Thought: Now that all elements are added, I should review and correct the code for the page to ensure it's properly structured and formatted.
Action: final_reviewer: [Full code of the page]
PAUSE

You will be called again with this:

Observation: Code reviewed and corrected

If you have all elements as requested, output it as the Answer.

Answer: Page created with a title, an introductory paragraph, a detailed essay about AI's impact on modern society, and an interactive button to generate AI facts. The code has been reviewed, corrected, and properly formatted to ensure it's executable.

Remember to use these actions as needed to fulfill the user's request for page content. Always use the final_reviewer action as the last step to ensure the code is properly structured and formatted.


"""

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # 
# llm_call:
# e.g., streamlit_coder: Add a button to the Streamlit app that, when clicked, triggers an LLM call to generate a random fact about AI. Use the `GroqCalls` function to make the LLM call within the generated code, like this:
#        if st.button('Generate AI Fact'):
#            fact = GroqCalls("Generate a random interesting fact about artificial intelligence")
#            st.write(fact)
# llm_call:
# e.g., streamlit_coder: Add a button to the Streamlit app that, when clicked, triggers an LLM call to generate a response based on the user's input. Use the `GroqCalls` function to make the LLM call within the generated code, like this:
#        if st.button('Generate Response'):
#            user_input = st.text_input("Enter your prompt")
#            prompt = f"Generate a response for the following input: {user_input}"
#            response = GroqCalls(prompt)
#            st.write(response)
# The llm_call action should be used within the streamlit_coder action to guide the generation of Streamlit code that incorporates LLM calls using the `GroqCalls` function. The generated code should:
# - Accept user input from the Streamlit app
# - Concatenate the user input with a predefined prompt to create a personalized prompt
# - Pass the concatenated prompt to the `GroqCalls` function to make the LLM call
# - Display the LLM response in the Streamlit app
# Ensure that the generated code is complete, executable, and properly utilizes the LLM responses based on the user's input.

# create_rag_page:
# e.g., create_rag_page: Build RAG with document
# Creates a new page with a RAG (Retrieval-Augmented Generation) chatbot based on the uploaded document. This action should only be used when a document has been uploaded by the user. The resulting page will include a chat interface where users can ask questions about the uploaded document.




########################################################################################################################
csv

import streamlit as st
from LLMCall import GroqCalls

import streamlit as st
from LLMCall import GroqCalls
import pandas as pd

def main():
    st.title("CSV File Uploader and Query Tool")

    uploaded_file = st.file_uploader("Upload a CSV file", type=["csv"])

    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.write("Dataframe Overview:")
        st.dataframe(df)

        question = st.text_input("Ask a question about the data:")

        if st.button("Submit"):
            if question:
                prompt = f"Write a summary for the user input: '{question}' based on the following data: {df.head()}"
                response = GroqCalls(prompt)
                st.write("Response from LLM:")
                st.write(response)
            else:
                st.warning("Please enter a question.")

if __name__ == "__main__":
    main()

################################################

import streamlit as st
from LLMCall import GroqCalls
from rag_tool import rag_tool
from langchain.schema import Document
import pickle
from pathlib import Path

import streamlit as st
from LLMCall import GroqCalls

def generate_jira_stories(project_details):
    prompt = f"Write detailed Jira stories based on the following project details: {project_details}"
    response = GroqCalls(prompt)
    return response

def prioritize_stories(stories):
    prompt = f"Prioritize the following Jira stories:\n{stories}"
    response = GroqCalls(prompt)
    return response

def assign_points(stories):
    prompt = f"Assign story points for the following Jira stories:\n{stories}"
    response = GroqCalls(prompt)
    return response

st.title("JiraBoy Tool")

st.write("Welcome to the JiraBoy tool! This application helps you create, prioritize, and assign points to Jira stories based on your project details. Please input your project details below:")

project_details = st.text_area("Project Details", "Enter the relevant details of your project here...")

if st.button("Generate Jira Stories"):
    if project_details:
        stories = generate_jira_stories(project_details)
        st.write("### Generated Jira Stories:")
        st.text_area("Jira Stories", stories, height=300)
        
        prioritized_stories = prioritize_stories(stories)
        st.write("### Prioritized Jira Stories:")
        st.text_area("Prioritized Jira Stories", prioritized_stories, height=300)

        stories_with_points = assign_points(prioritized_stories)
        st.write("### Jira Stories with Points:")
        st.text_area("Stories with Points", stories_with_points, height=300)
    else:
        st.warning("Please enter project details to generate Jira stories.")
        
st.write("### Instructions:")
st.write("1. Fill in the project details to help the tool generate relevant Jira stories.")
st.write("2. Click on 'Generate Jira Stories' to produce stories, prioritize them, and assign story points.")
st.write("3. Review the results in the text areas provided.")







########################################################################################################################
